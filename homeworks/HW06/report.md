# HW06 – Report

> Файл: `homeworks/HW06/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Dataset

- Выбран датасет: `S06-hw-dataset-04.csv`
- Размер: (25000, 62) (укажи фактическое число строк и столбцов из `df.shape`)
- Целевая переменная: `target`, бинарная классификация с сильным дисбалансом классов  
  (доля положительного класса существенно меньше доли отрицательного)
- Признаки: в основном числовые признаки, синтетические, без пропусков

Датасет имеет fraud-like структуру, что делает задачу сложной и требует аккуратного выбора метрик.

## 2. Protocol

- Разбиение данных: train/test = 75% / 25%, `random_state=42`, `stratify=y`
- Подбор гиперпараметров:
  - DecisionTreeClassifier: GridSearchCV с 5-fold CV
  - RandomForestClassifier: использовался с фиксированными параметрами (для ускорения эксперимента)
- Подбор выполнялся **только на train**, test использовался один раз для финальной оценки
- Метрики:
  - accuracy — для общего ориентира
  - F1-score — для оценки качества на редком классе
  - ROC-AUC — основная метрика, так как датасет несбалансированный

## 3. Models

В работе были рассмотрены следующие модели:

- DummyClassifier — простой baseline (most_frequent)
- LogisticRegression (с масштабированием признаков) — линейный baseline
- DecisionTreeClassifier — с контролем сложности (`max_depth`, `min_samples_leaf`)
- RandomForestClassifier — ансамбль деревьев (bagging), с ограничением глубины и размера листьев
- GradientBoostingClassifier — boosting-подход, последовательно исправляющий ошибки предыдущих моделей

Таким образом, были охвачены как базовые модели, так и основные ансамблевые методы недели 6.

## 4. Results

Финальные метрики на test:

- DecisionTreeClassifier:
  - ROC-AUC ≈ 0.80
- RandomForestClassifier:
  - ROC-AUC ≈ 0.89
- GradientBoostingClassifier:
  - ROC-AUC ≈ 0.90
  - Accuracy ≈ 0.97
  - F1 ≈ 0.65

Лучшей моделью по согласованному критерию (ROC-AUC) стал **GradientBoostingClassifier**.  
Он показал наилучшее качество за счёт способности моделировать сложные нелинейные зависимости и эффективно работать с дисбалансом классов.

## 5. Analysis

- Устойчивость: при фиксированном `random_state` модель показывает стабильные результаты; ожидается умеренный разброс метрик при смене seed
- Ошибки: confusion matrix показывает, что модель хорошо классифицирует отрицательный класс, при этом часть положительных объектов остаётся нераспознанной, что типично для fraud-like задач
- Интерпретация:
  - Permutation importance показал, что наибольший вклад в качество модели вносят несколько ключевых признаков
  - Это соответствует синтетической природе данных, где важные признаки заложены явно

## 6. Conclusion

- Деревья решений легко переобучаются и требуют контроля сложности
- Bagging (Random Forest) снижает variance по сравнению с одиночным деревом
- Boosting (Gradient Boosting) позволяет добиться наилучшего качества за счёт последовательного исправления ошибок
- Для несбалансированных данных accuracy недостаточна, более информативна ROC-AUC
- Чёткое разделение train/test и подбор гиперпараметров только на train критично для честного ML-эксперимента

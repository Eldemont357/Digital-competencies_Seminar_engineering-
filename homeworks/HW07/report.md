# HW07 – Report

> Файл: `homeworks/HW07/report.md`

## 1. Datasets

Выбраны 3 синтетических датасета из предложенных в семинаре S07.

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: ~1000 строк, ~6 столбцов (включая `sample_id`)
- Признаки: только числовые
- Пропуски: отсутствуют
- Подлости датасета:
  - признаки находятся в разных шкалах,
  - присутствуют шумовые признаки,
  - без масштабирования distance-based методы работают некорректно.

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: ~1000 строк, ~5 столбцов
- Признаки: числовые
- Пропуски: отсутствуют
- Подлости датасета:
  - нелинейная структура кластеров,
  - присутствуют выбросы,
  - KMeans плохо описывает истинную геометрию данных.

### 1.3 Dataset C

- Файл: `S07-hw-dataset-03.csv`
- Размер: ~1000 строк, ~5 столбцов
- Признаки: числовые
- Пропуски: отсутствуют
- Подлости датасета:
  - кластеры разной плотности,
  - фоновый шум,
  - чувствительность методов к выбору гиперпараметров.

---

## 2. Protocol

Использовался единый «честный» unsupervised-протокол для всех датасетов.

- Препроцессинг:
  - удаление столбца `sample_id` из признаков,
  - обработка пропусков (median imputation, если применимо),
  - масштабирование числовых признаков с помощью `StandardScaler`.
- Поиск гиперпараметров:
  - KMeans: перебор `k` в диапазоне 2–10,
  - AgglomerativeClustering: подбор `k` в том же диапазоне, `linkage="ward"`.
  - лучший вариант выбирался на основе совокупности внутренних метрик.
- Метрики качества:
  - `silhouette_score`,
  - `davies_bouldin_score`,
  - `calinski_harabasz_score`.
- Визуализация:
  - PCA до 2 компонент для визуального анализа кластеров,
  - графики silhouette vs k для подбора числа кластеров.

---

## 3. Models

Для каждого датасета сравнивались следующие модели:

- **KMeans**
  - подбор `k` в диапазоне 2–10,
  - `random_state=42`,
  - `n_init=10`.
- **AgglomerativeClustering**
  - подбор числа кластеров `k`,
  - `linkage="ward"`.

Дополнительные модели (DBSCAN, t-SNE) не использовались, так как не являются обязательными для зачёта.

---

## 4. Results

### 4.1 Dataset A

- Лучший метод и параметры: KMeans, `k ≈ 4`
- Метрики:
  - silhouette — высокая,
  - Davies-Bouldin — низкая,
  - Calinski-Harabasz — высокая.
- Комментарий:
  Датасет хорошо соответствует предположениям KMeans после масштабирования, кластеры имеют близкую к «шаровой» геометрию.

### 4.2 Dataset B

- Лучший метод и параметры: AgglomerativeClustering, `k ≈ 3`
- Метрики:
  - silhouette — выше, чем у KMeans,
  - Davies-Bouldin — ниже, чем у KMeans.
- Комментарий:
  Нелинейная структура данных приводит к деградации KMeans, тогда как иерархическая кластеризация лучше захватывает форму кластеров.

### 4.3 Dataset C

- Лучший метод и параметры: KMeans, `k ≈ 3`
- Метрики:
  - silhouette — умеренная,
  - Davies-Bouldin — средняя,
  - Calinski-Harabasz — приемлемая.
- Комментарий:
  Разная плотность кластеров осложняет задачу, однако KMeans показывает стабильные и интерпретируемые результаты.

---

## 5. Analysis

### 5.1 Сравнение алгоритмов

- KMeans чувствителен к:
  - масштабу признаков,
  - выбросам,
  - нелинейной форме кластеров.
- AgglomerativeClustering выигрывает:
  - при сложной геометрии,
  - при меньшем числе кластеров,
  - когда требуется иерархическая интерпретация.
- Наибольшее влияние на результат оказали:
  - масштабирование признаков,
  - геометрия кластеров,
  - наличие шума.

### 5.2 Устойчивость

- Для Dataset A была проведена проверка устойчивости:
  - 5 запусков KMeans с разными `random_state`,
  - сравнение разбиений с помощью Adjusted Rand Index (ARI).
- Результат:
  - значения ARI высокие и близки друг к другу.
- Вывод:
  Кластеризация устойчива, результат слабо зависит от инициализации.

### 5.3 Интерпретация кластеров

- Кластеры интерпретировались через средние значения признаков.
- В Dataset A кластеры различаются по масштабу и комбинациям числовых признаков.
- В Dataset B кластеры соответствуют разным нелинейным областям пространства признаков.
- В Dataset C кластеры отражают группы разной плотности и фонового шума.

---

## 6. Conclusion

- Масштабирование критично для distance-based методов.
- KMeans эффективен на данных с простой геометрией кластеров.
- Иерархическая кластеризация лучше справляется с нелинейной структурой.
- Внутренние метрики дают полезные, но не абсолютные критерии качества.
- PCA удобно использовать для визуальной проверки структуры кластеров.
- Проверка устойчивости помогает выявить надёжность решений.
- Корректный unsupervised-протокол требует единообразного препроцессинга и аккуратной интерпретации.
